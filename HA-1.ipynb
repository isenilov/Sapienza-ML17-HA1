{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML HA-1 #\n",
    "## by Ivan Senilov (1787618) ##\n",
    "\n",
    "The goal of this HA is to create a Malware classifier having dataset of features of Android apps with corresponding class of malware (or absence of malware). The [DREBIN](https://www.sec.cs.tu-bs.de/~danarp/drebin/download.html) dataset is used for the purpose and needs to be put in `drebin` subfolder with `drebin/feature_vectors` containing files with features.\n",
    "\n",
    "Unfortunately, local computer could handle only 2000 entries so for the training of the classifiers the Google Cloud VM with 8 cores and 32Gb (12Gb of which were occupied by the data) RAM was used.\n",
    "\n",
    "Let's import libraries for working with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dictionary with correspondance between file name with features and family of the malware and remove malwares with less than 20 entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 155 ms, sys: 8.25 ms, total: 163 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"drebin/sha256_family.csv\")\n",
    "num = data[\"family\"].value_counts() > 20\n",
    "\n",
    "for i in num.index:\n",
    "    if not num[i]:\n",
    "        data = data[data.family != i]\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract our features populating a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api_call': ['java/net/HttpURLConnection', 'android/telephony/TelephonyManager;->getDeviceId', 'android/net/ConnectivityManager;->getActiveNetworkInfo', 'android/content/ContentResolver;->openFileDescriptor', 'android/webkit/WebChromeClient;->onGeolocationPermissionsShowPrompt', 'android/content/Context;->startActivity', 'java/lang/Runtime;->exec', 'android/net/wifi/WifiManager;->getWifiState', 'android/net/wifi/WifiManager;->setWifiEnabled', 'android/app/NotificationManager;->notify'], 'permission': ['android.permission.READ_PHONE_STATE', 'android.permission.ACCESS_WIFI_STATE', 'android.permission.CHANGE_WIFI_STATE', 'android.permission.WRITE_EXTERNAL_STORAGE', 'android.permission.ACCESS_NETWORK_STATE', 'android.permission.INTERNET', 'android.permission.RECEIVE_BOOT_COMPLETED'], 'real_permission': ['android.permission.ACCESS_FINE_LOCATION', 'android.permission.READ_CONTACTS', 'android.permission.ACCESS_WIFI_STATE', 'android.permission.READ_PHONE_STATE', 'android.permission.VIBRATE', 'android.permission.CHANGE_WIFI_STATE', 'android.permission.ACCESS_NETWORK_STATE', 'android.permission.READ_LOGS', 'android.permission.INTERNET'], 'feature': ['android.hardware.touchscreen', 'android.hardware.wifi']} \n",
      "\n",
      "\n",
      "CPU times: user 1.42 s, sys: 562 ms, total: 1.98 s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = len(data)  # number of samples to train and test on\n",
    "\n",
    "X_temp = []\n",
    "y_temp = []\n",
    "feature_types = (\"api_call\", \"permission\", \"real_permission\", \"feature\")  # feature types we are interested in\n",
    "type_to_vec = {el:[] for el in feature_types}\n",
    "for i in range(N):\n",
    "    with open(\"drebin/feature_vectors/\" + data[\"sha256\"][i], 'r') as file:\n",
    "        lines = {el:[] for el in feature_types}\n",
    "        for line in file:\n",
    "            line = line.strip().split(\"::\")\n",
    "            if line[0] in feature_types:\n",
    "                lines[line[0]].append(line[1])\n",
    "                if line[1] not in type_to_vec:\n",
    "                    type_to_vec[line[0]].append(line[1])\n",
    "    X_temp.append(lines)\n",
    "    y_temp.append(data[\"family\"][i])\n",
    "print(X_temp[1], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make a categorical feature vector from them as described in [1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4785, 137648) \n",
      "\n",
      "\n",
      "CPU times: user 2.73 s, sys: 6.51 s, total: 9.25 s\n",
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "\n",
    "for i in range(len(X_temp)):\n",
    "    n = np.zeros(1)\n",
    "    for j in feature_types:\n",
    "        m = np.zeros(len(type_to_vec[j]))\n",
    "        for k in range(len(X_temp[i][j])):\n",
    "            m[type_to_vec[j].index(X_temp[i][j][k])] = 1\n",
    "        n = np.concatenate((n, m))\n",
    "    X.append(n)\n",
    "\n",
    "X = np.asarray(X)\n",
    "print(X.shape, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4,785 sampples with 137,648-dim (!) feature vectors.\n",
    "\n",
    "Labels are also transformed to categorical one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4785, 24) \n",
      "\n",
      "\n",
      "CPU times: user 260 ms, sys: 20.1 ms, total: 280 ms\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(le.fit_transform(y_temp).reshape((len(y_temp),1)))\n",
    "print(y.shape, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having 24 malware families, train SVM one-vs-all classifier on the data to have a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.948101265823 \n",
      "\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Plankton       1.00      0.87      0.93        30\n",
      "       DroidKungFu       0.96      0.90      0.93       114\n",
      "          Plankton       1.00      0.13      0.24        15\n",
      "         GinMaster       1.00      0.93      0.96        27\n",
      "           FakeDoc       0.99      0.99      0.99       206\n",
      "         GinMaster       0.94      0.76      0.84        21\n",
      "     FakeInstaller       1.00      0.98      0.99        46\n",
      "            Opfake       0.99      0.97      0.98       330\n",
      "     FakeInstaller       0.93      1.00      0.96        13\n",
      "            Opfake       0.78      0.95      0.86        19\n",
      "        BaseBridge       1.00      0.95      0.97        39\n",
      "        BaseBridge       0.97      0.97      0.97       115\n",
      "            Opfake       1.00      0.89      0.94        18\n",
      "     FakeInstaller       1.00      1.00      1.00        16\n",
      "              Adrd       1.00      0.96      0.98        52\n",
      "              Kmin       1.00      1.00      1.00        12\n",
      "         GinMaster       1.00      1.00      1.00         6\n",
      "              Adrd       1.00      0.98      0.99        43\n",
      "              Kmin       1.00      1.00      1.00        20\n",
      "           Geinimi       0.93      1.00      0.97       198\n",
      "        DroidDream       0.98      0.98      0.98       194\n",
      "     FakeInstaller       0.73      0.73      0.73        11\n",
      "        BaseBridge       0.90      1.00      0.95        18\n",
      "             Imlog       1.00      1.00      1.00        17\n",
      "\n",
      "       avg / total       0.97      0.96      0.96      1580\n",
      " \n",
      "\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "\n",
      "CPU times: user 43min 17s, sys: 1.12 s, total: 43min 18s\n",
      "Wall time: 43min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isenilov/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 24, does not match size of target_names, 4785\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = OneVsRestClassifier(SVC(kernel=\"linear\", random_state=42))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test), \"\\n\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=y_temp), \"\\n\\n\")\n",
    "print(clf.get_params()[\"estimator\"], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On all 4,785 samples we have 94.8% accuracy while training with default hyperparameters (printed below the stats). \n",
    "\n",
    "Let's try random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924683544304 \n",
      "\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Plankton       1.00      0.87      0.93        30\n",
      "       DroidKungFu       0.96      0.90      0.93       114\n",
      "          Plankton       1.00      0.13      0.24        15\n",
      "         GinMaster       1.00      0.93      0.96        27\n",
      "           FakeDoc       0.99      0.99      0.99       206\n",
      "         GinMaster       0.94      0.76      0.84        21\n",
      "     FakeInstaller       1.00      0.98      0.99        46\n",
      "            Opfake       0.99      0.97      0.98       330\n",
      "     FakeInstaller       0.93      1.00      0.96        13\n",
      "            Opfake       0.78      0.95      0.86        19\n",
      "        BaseBridge       1.00      0.95      0.97        39\n",
      "        BaseBridge       0.97      0.97      0.97       115\n",
      "            Opfake       1.00      0.89      0.94        18\n",
      "     FakeInstaller       1.00      1.00      1.00        16\n",
      "              Adrd       1.00      0.96      0.98        52\n",
      "              Kmin       1.00      1.00      1.00        12\n",
      "         GinMaster       1.00      1.00      1.00         6\n",
      "              Adrd       1.00      0.98      0.99        43\n",
      "              Kmin       1.00      1.00      1.00        20\n",
      "           Geinimi       0.93      1.00      0.97       198\n",
      "        DroidDream       0.98      0.98      0.98       194\n",
      "     FakeInstaller       0.73      0.73      0.73        11\n",
      "        BaseBridge       0.90      1.00      0.95        18\n",
      "             Imlog       1.00      1.00      1.00        17\n",
      "\n",
      "       avg / total       0.97      0.96      0.96      1580\n",
      " \n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "\n",
      "\n",
      "CPU times: user 12min 42s, sys: 30.8 s, total: 13min 13s\n",
      "Wall time: 13min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isenilov/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 24, does not match size of target_names, 4785\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf2 = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", clf2.score(X_test, y_test), \"\\n\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=y_temp), \"\\n\\n\")\n",
    "print(clf2.get_params()[\"estimator\"], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest of 10 trees yields 92.5%.\n",
    "\n",
    "Making the labels matrices dense in order to make Keras work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.todense()\n",
    "y_test = y_test.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third option is deep neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 137648)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8809536   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 8,815,256\n",
      "Trainable params: 8,815,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy 0.967721518535 \n",
      "\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          Plankton       1.00      0.97      0.98        30\n",
      "       DroidKungFu       0.94      0.94      0.94       114\n",
      "          Plankton       1.00      0.13      0.24        15\n",
      "         GinMaster       0.89      0.93      0.91        27\n",
      "           FakeDoc       0.98      0.99      0.98       206\n",
      "         GinMaster       1.00      0.81      0.89        21\n",
      "     FakeInstaller       1.00      0.98      0.99        46\n",
      "            Opfake       0.98      0.98      0.98       330\n",
      "     FakeInstaller       1.00      1.00      1.00        13\n",
      "            Opfake       0.78      0.95      0.86        19\n",
      "        BaseBridge       1.00      0.95      0.97        39\n",
      "        BaseBridge       0.99      0.98      0.99       115\n",
      "            Opfake       0.94      0.89      0.91        18\n",
      "     FakeInstaller       1.00      1.00      1.00        16\n",
      "              Adrd       0.98      0.98      0.98        52\n",
      "              Kmin       1.00      1.00      1.00        12\n",
      "         GinMaster       1.00      1.00      1.00         6\n",
      "              Adrd       1.00      0.98      0.99        43\n",
      "              Kmin       1.00      1.00      1.00        20\n",
      "           Geinimi       0.94      0.99      0.97       198\n",
      "        DroidDream       0.99      1.00      1.00       194\n",
      "     FakeInstaller       0.73      0.73      0.73        11\n",
      "        BaseBridge       0.95      1.00      0.97        18\n",
      "             Imlog       0.85      1.00      0.92        17\n",
      "\n",
      "       avg / total       0.97      0.97      0.96      1580\n",
      " \n",
      "\n",
      "\n",
      "CPU times: user 33min 22s, sys: 10min 28s, total: 43min 50s\n",
      "Wall time: 10min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isenilov/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 24, does not match size of target_names, 4785\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "#x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "predictions = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=128, verbose=0)\n",
    "y_pred = to_categorical(np.argmax(model.predict(X_test),axis=-1))\n",
    "print(\"Accuracy\", model.evaluate(X_test, y_test, batch_size=128, verbose=0)[1], \"\\n\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=y_temp), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Simple Neural Network with 3 layers gives us 96.8% accuracy, surpassing other classififcators we examined in this work so far.\n",
    "\n",
    "Concluding our experiments, we showed how to extract and preprocess features from the dataset and tested three classifiers on them. The best results were showed by the Neural Network. However, there may be place for improvement, for example by applying Convolutional Neural Network or experimenting with deeper architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K., & Siemens, C. E. R. T. (2014, February). DREBIN: Effective and Explainable Detection of Android Malware in Your Pocket. In NDSS.\n",
    "\n",
    "2. Spreitzenbarth, M., Freiling, F., Echtler, F., Schreck, T., & Hoffmann, J. (2013, March). Mobile-sandbox: having a deeper look into android applications. In Proceedings of the 28th Annual ACM Symposium on Applied Computing (pp. 1808-1815). ACM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
